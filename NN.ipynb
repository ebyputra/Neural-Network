{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730510a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Umur</th>\n",
       "      <th>Tinggi Badan</th>\n",
       "      <th>Berat Badan</th>\n",
       "      <th>Pilek</th>\n",
       "      <th>Demam</th>\n",
       "      <th>Batuk</th>\n",
       "      <th>Sesak Nafas</th>\n",
       "      <th>Keluhan Lain</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>155</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>154</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>163</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>165</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>166</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Umur  Tinggi Badan  Berat Badan  Pilek  Demam  Batuk  Sesak Nafas  \\\n",
       "0       0    50           155           56      0      0      0            0   \n",
       "1       0    31           154           60      0      0      0            0   \n",
       "2       1    32           163           56      0      0      0            0   \n",
       "3       1    21           165           53      0      0      0            0   \n",
       "4       1    33           166           62      0      0      0            0   \n",
       "\n",
       "   Keluhan Lain  Status  \n",
       "0             1       0  \n",
       "1             1       0  \n",
       "2             1       0  \n",
       "3             0       0  \n",
       "4             1       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('klass.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2ff498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   Gender        248 non-null    int64\n",
      " 1   Umur          248 non-null    int64\n",
      " 2   Tinggi Badan  248 non-null    int64\n",
      " 3   Berat Badan   248 non-null    int64\n",
      " 4   Pilek         248 non-null    int64\n",
      " 5   Demam         248 non-null    int64\n",
      " 6   Batuk         248 non-null    int64\n",
      " 7   Sesak Nafas   248 non-null    int64\n",
      " 8   Keluhan Lain  248 non-null    int64\n",
      " 9   Status        248 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b706c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 248, D: 10\n"
     ]
    }
   ],
   "source": [
    "N, D = df.shape\n",
    "print('N: %d, D: %d' %(N, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f550f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 10) (186, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df, test_size=0.25, random_state=2)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06d6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 10) (62, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b7a8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Gender  Umur  Tinggi Badan  Berat Badan  Pilek  Demam  Batuk  \\\n",
      "18        0    33           157           57      0      0      0   \n",
      "64        1    42           162           62      1      1      0   \n",
      "5         0    30           162           54      0      0      0   \n",
      "85        1    27           159           63      0      0      0   \n",
      "2         1    32           163           56      0      0      0   \n",
      "..      ...   ...           ...          ...    ...    ...    ...   \n",
      "22        1    41           157           71      0      0      0   \n",
      "72        1    42           160           69      0      0      0   \n",
      "237       0    23           158           77      0      0      0   \n",
      "15        1    32           166           66      0      0      0   \n",
      "168       0    29           160           69      0      0      0   \n",
      "\n",
      "     Sesak Nafas  Keluhan Lain  Status  \n",
      "18             0             1       0  \n",
      "64             0             1       1  \n",
      "5              0             1       0  \n",
      "85             0             1       0  \n",
      "2              0             1       0  \n",
      "..           ...           ...     ...  \n",
      "22             0             1       0  \n",
      "72             0             1       0  \n",
      "237            0             0       0  \n",
      "15             0             1       0  \n",
      "168            0             0       0  \n",
      "\n",
      "[186 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c47ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 9)\n",
      "[[  0  33 157 ...   0   0   1]\n",
      " [  1  42 162 ...   0   0   1]\n",
      " [  0  30 162 ...   0   0   1]\n",
      " ...\n",
      " [  0  23 158 ...   0   0   0]\n",
      " [  1  32 166 ...   0   0   1]\n",
      " [  0  29 160 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "X_train1=X_train.values\n",
    "X_train1=np.delete(X_train1, 9,axis=1)\n",
    "y_train1=X_train['Status'].values\n",
    "print(X_train1.shape)\n",
    "print(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e576e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 9)\n",
      "[0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "X_test1=X_test.values\n",
    "X_test1=np.delete(X_test1, 9, axis=1)\n",
    "y_test1= X_test['Status'].values\n",
    "print(X_test1.shape)\n",
    "print(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e0139c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.25       0.21428571 ... 0.         0.         1.        ]\n",
      " [1.         0.4375     0.57142857 ... 0.         0.         1.        ]\n",
      " [0.         0.1875     0.57142857 ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.         0.04166667 0.28571429 ... 0.         0.         0.        ]\n",
      " [1.         0.22916667 0.85714286 ... 0.         0.         1.        ]\n",
      " [0.         0.16666667 0.42857143 ... 0.         0.         0.        ]]\n",
      "[[1.         0.86666667 0.5        0.36       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [1.         0.         0.625      0.44       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.44444444 0.625      0.44       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [1.         0.02222222 0.6875     0.48       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.28888889 0.6875     0.4        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.24444444 0.625      0.28       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.08888889 0.5        0.28       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.86666667 0.375      0.84       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.26666667 0.6875     0.56       0.         1.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.02222222 0.0625     0.8        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.2        0.6875     0.04       1.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.37777778 0.0625     0.56       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.04444444 0.5625     0.32       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.33333333 0.5625     0.48       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.4        0.5        0.52       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.         0.6875     0.04       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.11111111 0.375      0.56       0.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.22222222 1.         0.68       1.         0.\n",
      "  1.         1.         1.        ]\n",
      " [1.         1.         0.5625     0.84       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.48888889 0.5        0.92       1.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.55555556 0.375      0.68       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [1.         0.33333333 0.5625     0.44       1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [1.         0.13333333 0.625      0.32       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.66666667 0.6875     0.8        0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.02222222 0.25       0.64       0.         0.\n",
      "  0.         1.         1.        ]\n",
      " [0.         0.         0.5        0.8        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.82222222 0.5        0.44       0.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.02222222 0.5625     0.48       1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [1.         0.13333333 0.375      1.         0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.22222222 0.5625     0.4        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.84444444 0.8125     0.         0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.11111111 0.875      0.4        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.35555556 0.75       0.44       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.35555556 0.6875     0.96       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [1.         0.04444444 0.5625     0.68       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.11111111 0.8125     0.64       1.         1.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.37777778 0.375      0.4        0.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.17777778 0.5        0.16       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.04444444 0.625      0.68       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.02222222 0.5        0.92       0.         0.\n",
      "  1.         0.         1.        ]\n",
      " [1.         0.66666667 0.6875     0.44       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.04444444 0.25       0.88       1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [1.         0.24444444 0.375      0.44       1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [1.         0.37777778 0.3125     0.8        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.2        0.5625     0.44       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.33333333 0.6875     0.32       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [0.         0.08888889 0.         0.36       1.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.44444444 0.8125     0.88       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.24444444 0.8125     0.4        0.         0.\n",
      "  1.         0.         1.        ]\n",
      " [1.         0.66666667 0.5        0.96       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.42222222 0.4375     0.52       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.28888889 0.5        0.28       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [1.         0.46666667 0.3125     0.84       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.08888889 0.875      0.44       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.22222222 0.3125     0.48       1.         0.\n",
      "  1.         1.         1.        ]\n",
      " [1.         0.42222222 0.5        0.64       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.35555556 0.4375     0.84       0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.11111111 0.3125     0.56       0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.8        0.4375     0.24       1.         1.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.8        0.75       0.2        0.         0.\n",
      "  0.         0.         1.        ]\n",
      " [1.         0.37777778 0.6875     0.16       1.         0.\n",
      "  1.         0.         0.        ]\n",
      " [0.         0.06666667 0.4375     0.52       0.         1.\n",
      "  0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train1=MinMaxScaler().fit_transform(X_train1)\n",
    "X_test1=MinMaxScaler().fit_transform(X_test1)\n",
    "print(X_train1)\n",
    "print(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ca56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, activation='relu', input_shape=(9,)))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca13a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 12)                120       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305\n",
      "Trainable params: 305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8cf871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 4ms/step - loss: 0.6828 - accuracy: 0.7634\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7634\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.7634\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7634\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7634\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7688\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7742\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7849\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8280\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8656\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8656\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8710\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8817\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8925\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.9032\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.9194\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.9194\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3232 - accuracy: 0.9194\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.9247\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.9247\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.9247\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2887 - accuracy: 0.9247\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.9247\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.9247\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2702 - accuracy: 0.9247\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.9247\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.9247\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.9247\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2532 - accuracy: 0.9247\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2512 - accuracy: 0.9247\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2482 - accuracy: 0.9247\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2446 - accuracy: 0.9247\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.9247\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9247\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2378 - accuracy: 0.9247\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9247\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.9247\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9247\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2326 - accuracy: 0.9247\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2312 - accuracy: 0.9247\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2306 - accuracy: 0.9247\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2290 - accuracy: 0.9247\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2273 - accuracy: 0.9247\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2261 - accuracy: 0.9247\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2249 - accuracy: 0.9301\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2249 - accuracy: 0.9301\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9301\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9301\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9301\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9301\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9247\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9247\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2186 - accuracy: 0.9301\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2180 - accuracy: 0.9247\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.9247\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9247\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9301\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9301\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9247\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9247\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9301\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9301\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2140 - accuracy: 0.9301\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9247\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9247\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9301\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9301\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9301\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9301\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9301\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9301\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9247\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9301\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9301\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9301\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9247\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9301\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9301\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9301\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9301\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9301\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9301\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9301\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9301\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9301\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9301\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9301\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9301\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9301\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9301\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9301\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2056 - accuracy: 0.9301\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.9301\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2110 - accuracy: 0.9301\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2068 - accuracy: 0.9301\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9301\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9301\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9301\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9301\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9301\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9301\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9301\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9301\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9301\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9301\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9301\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9301\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9301\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9301\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.9301\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9301\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9301\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9301\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9301\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9301\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9301\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9301\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9301\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9301\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9301\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9301\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9301\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9301\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9301\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9301\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9301\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9301\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9301\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9301\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9301\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9301\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9301\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9301\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9301\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9301\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9301\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9247\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9301\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9301\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9301\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9301\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9301\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9301\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9301\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9301\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9247\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.9301\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9355\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9301\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1888 - accuracy: 0.9301\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9301\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9301\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9301\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9301\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9301\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9301\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1881 - accuracy: 0.9301\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9301\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9301\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9301\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1855 - accuracy: 0.9301\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9301\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9301\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9301\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9301\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9301\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9301\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9301\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9355\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9355\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9355\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9301\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9355\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.9355\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9301\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9301\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9355\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.9355\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9301\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9355\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1806 - accuracy: 0.9355\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9355\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9301\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1821 - accuracy: 0.9355\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9355\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9355\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9301\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9355\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9355\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9355\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9355\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9355\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9355\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9355\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9355\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9409\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.9355\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9462\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9355\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9355\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1, epochs=200, verbose=1, batch_size=20)\n",
    "\n",
    "y_pred = model.predict(X_test1)\n",
    "y_pred = y_pred >= 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c968a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\By\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.1, max_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.1, max_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.1, max_iter=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.1, max_iter=100)\n",
    "clf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc2fb59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "round(accuracy_score(y_test1, y_pred), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d367cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        46\n",
      "           1       0.92      0.75      0.83        16\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.92      0.86      0.89        62\n",
      "weighted avg       0.92      0.92      0.92        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
